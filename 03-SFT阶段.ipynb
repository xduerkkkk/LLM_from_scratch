{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "from contextlib import nullcontext\n",
    "import time\n",
    "from tqdm.notebook import tqdm\n",
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 环境与设备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available: True\n",
      "Number of GPUs: 1\n",
      "  GPU 0: NVIDIA GeForce RTX 4090\n",
      "    Memory: 23.53 GB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(f\"CUDA is available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"Number of GPUs: {torch.cuda.device_count()}\")\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        print(f\"  GPU {i}: {torch.cuda.get_device_name(i)}\")\n",
    "        print(f\"    Memory: {torch.cuda.get_device_properties(i).total_memory / (1024**3):.2f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 参数配置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11303/3218077156.py:19: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  ctx = nullcontext() if device == \"cpu\" else torch.cuda.amp.autocast()\n"
     ]
    }
   ],
   "source": [
    "from model.model_minimind import MiniMindConfig\n",
    "class TrainArgs():\n",
    "    #文件管理\n",
    "    out_dir = './sft_output'\n",
    "    checkpoint_path = \"./sft_output/latest_checkpoint.pth\"\n",
    "    data_path = 'sft_1024.jsonl'\n",
    "    #神经网络训练管理\n",
    "    epochs = 2\n",
    "    batch_size = 128\n",
    "    accumulation_steps = 4\n",
    "    learning_rate = 5e-6\n",
    "    warm_up = 0\n",
    "    grad_clip = 1\n",
    "    dtype = 'bfloat16'\n",
    "    device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "    num_workers = min(8, os.cpu_count())\n",
    "    log_interval = 60\n",
    "    save_interval = 2000\n",
    "    ctx = nullcontext() if device == \"cpu\" else torch.cuda.amp.autocast()\n",
    "class LLMargs():\n",
    "    use_moe = False\n",
    "    hidden_size = 512\n",
    "    num_hidden_layers = 8\n",
    "    \n",
    "\n",
    "lm_config = MiniMindConfig(use_moe=LLMargs.use_moe,hidden_size=LLMargs.hidden_size,num_hidden_layers=LLMargs.num_hidden_layers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "os.makedirs(TrainArgs.out_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 加载模型与数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "加载模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from model.model_minimind import MiniMindConfig, MiniMindForCausalLM\n",
    "tokenizer = AutoTokenizer.from_pretrained('model')\n",
    "model = MiniMindForCausalLM(lm_config).to(TrainArgs.device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading checkpoint from pretrain_output/latest_checkpoint.pth...\n",
      "Checkpoint loaded successfully.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MiniMindForCausalLM(\n",
       "  (model): MiniMindModel(\n",
       "    (embed_tokens): Embedding(6400, 512)\n",
       "    (dropout): Dropout(p=0.0, inplace=False)\n",
       "    (layers): ModuleList(\n",
       "      (0-7): 8 x MiniMindBlock(\n",
       "        (self_attn): Attention(\n",
       "          (q_proj): Linear(in_features=512, out_features=512, bias=False)\n",
       "          (k_proj): Linear(in_features=512, out_features=128, bias=False)\n",
       "          (v_proj): Linear(in_features=512, out_features=128, bias=False)\n",
       "          (o_proj): Linear(in_features=512, out_features=512, bias=False)\n",
       "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (input_layernorm): RMSNorm()\n",
       "        (post_attention_layernorm): RMSNorm()\n",
       "        (mlp): FeedForward(\n",
       "          (gate_proj): Linear(in_features=512, out_features=1408, bias=False)\n",
       "          (down_proj): Linear(in_features=1408, out_features=512, bias=False)\n",
       "          (up_proj): Linear(in_features=512, out_features=1408, bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (norm): RMSNorm()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=512, out_features=6400, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "ckp = 'pretrain_output/latest_checkpoint.pth'\n",
    "# 1. 加载完整的 checkpoint 字典，并指明 weights_only=False\n",
    "print(f\"Loading checkpoint from {ckp}...\")\n",
    "checkpoint = torch.load(ckp, map_location=TrainArgs.device, weights_only=False)\n",
    "\n",
    "# 2. 从字典中提取模型的 state_dict 来加载\n",
    "model.load_state_dict(checkpoint['model'], strict=True)\n",
    "\n",
    "print(\"Checkpoint loaded successfully.\")\n",
    "model.to(TrainArgs.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MiniMindForCausalLM(\n",
      "  (model): MiniMindModel(\n",
      "    (embed_tokens): Embedding(6400, 512)\n",
      "    (dropout): Dropout(p=0.0, inplace=False)\n",
      "    (layers): ModuleList(\n",
      "      (0-7): 8 x MiniMindBlock(\n",
      "        (self_attn): Attention(\n",
      "          (q_proj): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (k_proj): Linear(in_features=512, out_features=128, bias=False)\n",
      "          (v_proj): Linear(in_features=512, out_features=128, bias=False)\n",
      "          (o_proj): Linear(in_features=512, out_features=512, bias=False)\n",
      "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (input_layernorm): RMSNorm()\n",
      "        (post_attention_layernorm): RMSNorm()\n",
      "        (mlp): FeedForward(\n",
      "          (gate_proj): Linear(in_features=512, out_features=1408, bias=False)\n",
      "          (down_proj): Linear(in_features=1408, out_features=512, bias=False)\n",
      "          (up_proj): Linear(in_features=512, out_features=1408, bias=False)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (norm): RMSNorm()\n",
      "  )\n",
      "  (lm_head): Linear(in_features=512, out_features=6400, bias=False)\n",
      ")\n",
      "模型总参数量 (Total Parameters): 25,829,888\n",
      "可训练参数量 (Trainable Parameters): 25,829,888\n"
     ]
    }
   ],
   "source": [
    "print(model)\n",
    "\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "\n",
    "# 打印结果，使用 f-string 的格式化功能让数字更易读（例如，加上千位分隔符）\n",
    "print(f\"模型总参数量 (Total Parameters): {total_params:,}\")\n",
    "\n",
    "# 如果你还想区分“可训练参数”，可以这样做：\n",
    "# 在大多数情况下，总参数量和可训练参数量是一样的。\n",
    "# 除非你手动设置了某些参数的 requires_grad=False (冻结了某些层)\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"可训练参数量 (Trainable Parameters): {trainable_params:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "加载数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "import json\n",
    "class SFTDataset(Dataset):\n",
    "    def __init__(self,  tokenizer,data_path, max_length=1024):\n",
    "        super().__init__()\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.samples = self.load_data(data_path)\n",
    "        self.bos_id = tokenizer('<|im_start|>assistant', add_special_tokens=False).input_ids\n",
    "        self.eos_id = tokenizer('<|im_end|>', add_special_tokens=False).input_ids\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def load_data(self, data_path):\n",
    "        samples = []\n",
    "        with open(data_path, 'r', encoding='utf-8') as f:\n",
    "            for line_num, line in enumerate(f, 1):\n",
    "                data = json.loads(line.strip())\n",
    "                samples.append(data)\n",
    "        return samples\n",
    "\n",
    "    def _create_chat_prompt(self, conversations):\n",
    "        \"\"\"构建符合ChatML格式的对话\"\"\"\n",
    "        messages = []\n",
    "        for i, turn in enumerate(conversations):\n",
    "            role = 'user' if i % 2 == 0 else 'assistant'\n",
    "            messages.append({\"role\": role, \"content\": turn['content']})\n",
    "        return self.tokenizer.apply_chat_template(\n",
    "            messages,\n",
    "            tokenize=False,\n",
    "            add_generation_prompt=False\n",
    "        )\n",
    "\n",
    "    def _generate_loss_mask(self, input_ids):\n",
    "        loss_mask = [0] * len(input_ids)\n",
    "        i = 0\n",
    "        while i < len(input_ids):\n",
    "            if input_ids[i:i + len(self.bos_id)] == self.bos_id:\n",
    "                start = i + len(self.bos_id)\n",
    "                end = start\n",
    "                while end < len(input_ids):\n",
    "                    if input_ids[end:end + len(self.eos_id)] == self.eos_id:\n",
    "                        break\n",
    "                    end += 1\n",
    "                for j in range(start + 1, min(end + len(self.eos_id) + 1, self.max_length)):\n",
    "                    loss_mask[j] = 1\n",
    "                i = end + len(self.eos_id) if end < len(input_ids) else len(input_ids)\n",
    "            else:\n",
    "                i += 1\n",
    "        return loss_mask\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        sample = self.samples[index]\n",
    "        \n",
    "        # 构建对话提示\n",
    "        prompt = self._create_chat_prompt(sample['conversations'])\n",
    "        input_ids = self.tokenizer(prompt).input_ids[:self.max_length]\n",
    "        input_ids += [self.tokenizer.pad_token_id] * (self.max_length - len(input_ids))\n",
    "\n",
    "        # 生成动态损失掩码\n",
    "        loss_mask = self._generate_loss_mask(input_ids)\n",
    "\n",
    "        # 构建训练数据\n",
    "        X = torch.tensor(input_ids[:-1], dtype=torch.long)\n",
    "        Y = torch.tensor(input_ids[1:], dtype=torch.long)\n",
    "        loss_mask = torch.tensor(loss_mask[1:], dtype=torch.long)  # 对齐预测位置\n",
    " # 对齐预测位置\n",
    "\n",
    "        return X, Y, loss_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = SFTDataset(tokenizer,TrainArgs.data_path,max_length=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([   1,   85,  736,  201,   59,  292,  389,  260, 3836, 1861,  501,    2,\n",
      "         201,    1,  320,  275,  201, 1936,  343,  384, 4451,  260, 1482,  273,\n",
      "         327, 3717,  295,  614, 2143, 1833,  730,  281, 5171,   14, 6194,   33,\n",
      "           2,  201,    1, 1078,  538,  501,  201, 5042, 4451,  260, 1482,  273,\n",
      "         327, 3717, 1833,  730,  281, 5171,  958,  261, 4109, 4941,   11,  295,\n",
      "         614, 2143,   14,  363,  343,  813,  276, 3745, 3830,  327,   66,  461,\n",
      "        6139,   14,  896, 3198, 2514, 2356,  325,  524,  290, 4451, 1482,  273,\n",
      "         327, 1921, 2781,   16, 1193, 1860,   85,  822,  363,  343, 1004,  470,\n",
      "          28,  201,  201, 1638, 4751,  201,  334, 1519, 1482,  273,  327,  201,\n",
      "         201,    5,  886, 3877,  429,  260, 1482,  273,  327,  696, 1841,  275,\n",
      "        1833,  730,  281, 5171,   14, 6194,  201, 3830,  327,   65, 3267, 1485,\n",
      "         901, 1482,  273,  327,   16, 3830, 1131,   10,   19,   14, 5171,   11,\n",
      "         201,  201, 2809,   10, 3830,  327,   65, 3267, 1485,   11,  201, 1638,\n",
      "         201,  201,    5,    5,    5, 3206,  711,  280,  337,   28,  201,   15,\n",
      "        3745, 3830,  327,   16, 3830, 1131,   10,   67,   14,  297,   11,   66,\n",
      "        2099,  373,  915,  260, 1482,  273,  327,  696, 1841,  275, 3745,   48,\n",
      "          66,  751,  349, 3745,   67, 3386,   31,  933, 3386,   31,  297,   66,\n",
      "          16,  637, 3879,  470, 2990, 2499,  276, 2651,   82, 4829,   85, 3745,\n",
      "          67,   66,  281, 3745,   68,   66,   16,  201,  201, 3721,  272, 3549,\n",
      "        1036, 3330,  260, 1482,  273,  327,  696, 1841,  275, 1833,  730,  281,\n",
      "        5171, 1875, 1100,  363, 5461,  470,   16,    2,  201,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0]), tensor([  85,  736,  201,   59,  292,  389,  260, 3836, 1861,  501,    2,  201,\n",
      "           1,  320,  275,  201, 1936,  343,  384, 4451,  260, 1482,  273,  327,\n",
      "        3717,  295,  614, 2143, 1833,  730,  281, 5171,   14, 6194,   33,    2,\n",
      "         201,    1, 1078,  538,  501,  201, 5042, 4451,  260, 1482,  273,  327,\n",
      "        3717, 1833,  730,  281, 5171,  958,  261, 4109, 4941,   11,  295,  614,\n",
      "        2143,   14,  363,  343,  813,  276, 3745, 3830,  327,   66,  461, 6139,\n",
      "          14,  896, 3198, 2514, 2356,  325,  524,  290, 4451, 1482,  273,  327,\n",
      "        1921, 2781,   16, 1193, 1860,   85,  822,  363,  343, 1004,  470,   28,\n",
      "         201,  201, 1638, 4751,  201,  334, 1519, 1482,  273,  327,  201,  201,\n",
      "           5,  886, 3877,  429,  260, 1482,  273,  327,  696, 1841,  275, 1833,\n",
      "         730,  281, 5171,   14, 6194,  201, 3830,  327,   65, 3267, 1485,  901,\n",
      "        1482,  273,  327,   16, 3830, 1131,   10,   19,   14, 5171,   11,  201,\n",
      "         201, 2809,   10, 3830,  327,   65, 3267, 1485,   11,  201, 1638,  201,\n",
      "         201,    5,    5,    5, 3206,  711,  280,  337,   28,  201,   15, 3745,\n",
      "        3830,  327,   16, 3830, 1131,   10,   67,   14,  297,   11,   66, 2099,\n",
      "         373,  915,  260, 1482,  273,  327,  696, 1841,  275, 3745,   48,   66,\n",
      "         751,  349, 3745,   67, 3386,   31,  933, 3386,   31,  297,   66,   16,\n",
      "         637, 3879,  470, 2990, 2499,  276, 2651,   82, 4829,   85, 3745,   67,\n",
      "          66,  281, 3745,   68,   66,   16,  201,  201, 3721,  272, 3549, 1036,\n",
      "        3330,  260, 1482,  273,  327,  696, 1841,  275, 1833,  730,  281, 5171,\n",
      "        1875, 1100,  363, 5461,  470,   16,    2,  201,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0]), tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0]))\n",
      "数据集总长度为4196362\n"
     ]
    }
   ],
   "source": [
    "print(f'{train_ds[1]}\\n数据集总长度为{len(train_ds)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds = Subset(train_ds,range(1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "加载dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(\n",
    "    test_ds,\n",
    "    batch_size = TrainArgs.batch_size,\n",
    "    shuffle = True,\n",
    "    num_workers = TrainArgs.num_workers,\n",
    "    pin_memory= True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    train_ds,\n",
    "    batch_size = TrainArgs.batch_size,\n",
    "    shuffle = True,\n",
    "    num_workers = TrainArgs.num_workers,\n",
    "    pin_memory= True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "检查一下"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0:\n",
      "  X_batch shape: torch.Size([128, 511])\n",
      "  Y_batch shape: torch.Size([128, 511])\n",
      "  loss_mask_batch shape: torch.Size([128, 511])\n"
     ]
    }
   ],
   "source": [
    "tag = False\n",
    "for batch_idx, (X_batch, Y_batch, loss_mask_batch) in enumerate(train_loader):\n",
    "    if not tag:\n",
    "        print(f\"Batch {batch_idx}:\")\n",
    "        print(f\"  X_batch shape: {X_batch.shape}\")\n",
    "        print(f\"  Y_batch shape: {Y_batch.shape}\")\n",
    "        print(f\"  loss_mask_batch shape: {loss_mask_batch.shape}\")\n",
    "        tag = True\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0:\n",
      "  X_batch shape: torch.Size([128, 511])\n",
      "  Y_batch shape: torch.Size([128, 511])\n",
      "  loss_mask_batch shape: torch.Size([128, 511])\n"
     ]
    }
   ],
   "source": [
    "tag = False\n",
    "for batch_idx, (X_batch, Y_batch, loss_mask_batch) in enumerate(test_loader):\n",
    "    if not tag:\n",
    "        print(f\"Batch {batch_idx}:\")\n",
    "        print(f\"  X_batch shape: {X_batch.shape}\")\n",
    "        print(f\"  Y_batch shape: {Y_batch.shape}\")\n",
    "        print(f\"  loss_mask_batch shape: {loss_mask_batch.shape}\")\n",
    "        tag = True\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11303/2396107109.py:7: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler(enabled=(TrainArgs.dtype in ['float16', 'bfloat16']))\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "from torch import optim\n",
    "def get_lr(current_step, total_steps, lr):\n",
    "    return lr / 10 + 0.5 * lr * (1 + math.cos(math.pi * current_step / total_steps))\n",
    "optimizer = optim.AdamW(model.parameters(), lr=TrainArgs.learning_rate)\n",
    "#据模型在训练数据上的表现来调整模型的参数  训练的一个大脑\n",
    "scaler = torch.cuda.amp.GradScaler(enabled=(TrainArgs.dtype in ['float16', 'bfloat16']))\n",
    "#自动混合精度训练工具 训练的一个助手"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d8463b6fe984ee3b97d25aa99b2c256",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21fb153d8c7d4230b529a561165e6f29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">swanlab</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">:</span> Tracking run with swanlab version <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6</span>.<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;34mswanlab\u001b[0m\u001b[1;39m:\u001b[0m Tracking run with swanlab version \u001b[1;36m0.6\u001b[0m.\u001b[1;36m7\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">swanlab</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">:</span> Run data will be saved locally in <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">/root/LLM_from_scratch/swanlog/run-20250725_103746-uqsu43c0ivhjabvngqs2n</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;34mswanlab\u001b[0m\u001b[1;39m:\u001b[0m Run data will be saved locally in \u001b[1;35m/root/LLM_from_scratch/swanlog/run-20250725_103746-uqsu43c0ivhjabvngqs2n\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">swanlab</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">:</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\"> </span>👋 Hi <span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">kkaiaiai</span>,welcome to swanlab!\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;34mswanlab\u001b[0m\u001b[1;39m:\u001b[0m\u001b[1;34m \u001b[0m👋 Hi \u001b[1;39mkkaiaiai\u001b[0m,welcome to swanlab!\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">swanlab</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">:</span> Syncing run <span style=\"color: #808000; text-decoration-color: #808000\">MiniMind-SFT</span> to the cloud\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;34mswanlab\u001b[0m\u001b[1;39m:\u001b[0m Syncing run \u001b[33mMiniMind-SFT\u001b[0m to the cloud\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">swanlab</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">:</span> 🏠 View project at <span style=\"color: #000080; text-decoration-color: #000080; text-decoration: underline\">https://swanlab.cn/@kkaiaiai/MiniMind-SFT</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;34mswanlab\u001b[0m\u001b[1;39m:\u001b[0m 🏠 View project at \u001b[4;34mhttps://swanlab.cn/@kkaiaiai/MiniMind-SFT\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">swanlab</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">:</span> 🚀 View run at <span style=\"color: #000080; text-decoration-color: #000080; text-decoration: underline\">https://swanlab.cn/@kkaiaiai/MiniMind-SFT/runs/uqsu43c0ivhjabvngqs2n</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;34mswanlab\u001b[0m\u001b[1;39m:\u001b[0m 🚀 View run at \u001b[4;34mhttps://swanlab.cn/@kkaiaiai/MiniMind-SFT/runs/uqsu43c0ivhjabvngqs2n\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<!DOCTYPE html>\n",
       "<html lang=\"en\">\n",
       "<head>\n",
       "    <meta charset=\"UTF-8\">\n",
       "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
       "    <title>Show Iframe</title>\n",
       "    \n",
       "        <script>\n",
       "            function showIframe() {\n",
       "                var iframeHtml = '<iframe src=\"https://swanlab.cn/@kkaiaiai/MiniMind-SFT/runs/uqsu43c0ivhjabvngqs2n\" width=100% height=\"600\" frameborder=\"no\"></iframe>';\n",
       "                document.getElementById('iframeContainer').innerHTML = iframeHtml;\n",
       "            }\n",
       "        </script>\n",
       "        \n",
       "</head>\n",
       "<body>\n",
       "    <style>\n",
       "        .interactive-button {\n",
       "            display: flex;\n",
       "            align-items: center;\n",
       "            height: 36px;\n",
       "            border: 0px;\n",
       "            background-color: #2c8f63;\n",
       "            color: white;\n",
       "            padding: 10px 20px;\n",
       "            transition: background-color 0.3s, transform 0.2s;\n",
       "        }\n",
       "\n",
       "        .interactive-button:hover {\n",
       "            background-color: #5cab87;\n",
       "            cursor: pointer;\n",
       "        }\n",
       "\n",
       "        .interactive-button:active { background-color: #217952; transform: scale(0.96); } </style> <br> <button \n",
       "        onclick=\"showIframe()\" class=\"interactive-button\"> <svg style=\"height: 16px; margin-right: 8px;\" viewBox=\"0 0 \n",
       "        46 46\" fill=\"none\"> <path d=\"M10.8439 21.1974C10.6414 21.2854 10.4477 21.3925 10.2655 21.5173L10.2069 \n",
       "        21.5652C10.1839 21.58 10.1625 21.5969 10.1429 21.6159C6.29135 24.6118 4.22831 29.4416 5.32646 34.282C5.94656 \n",
       "        37.0577 7.50461 39.5348 9.73801 41.2958C11.9714 43.0568 14.7436 43.994 17.5874 43.9495H18.0219C19.8864 \n",
       "        43.8697 21.7087 43.3694 23.3526 42.486C24.9964 41.6026 26.4193 40.3589 27.5147 38.848C28.61 37.3371 29.3496 \n",
       "        35.598 29.678 33.761C30.0065 31.9239 29.9153 30.0363 29.4112 28.2395C28.9181 26.4723 27.8919 24.8437 26.9937 \n",
       "        23.2551C25.4158 20.4653 23.8343 17.6764 22.2492 14.8884C21.7801 14.0647 21.3057 13.2465 20.8419 \n",
       "        12.4228C20.2315 11.3353 19.2746 10.1519 19.224 8.86183C19.1733 7.57176 20.2235 6.32701 21.5082 \n",
       "        6.07912C23.9284 5.61801 25.0639 8.24078 25.0693 8.23812C25.363 8.94035 25.9123 9.50489 26.6063 \n",
       "        9.81764C27.3002 10.1304 28.087 10.168 28.8077 9.92298C29.5283 9.67791 30.1291 9.1684 30.4885 8.49743C30.8479 \n",
       "        7.82646 30.9392 7.04405 30.7439 6.30835C30.1514 4.37314 28.9133 2.69953 27.2363 1.56656C25.7615 0.511704 \n",
       "        23.9847 -0.0372109 22.1719 0.00195984C20.9049 0.00893199 19.6532 0.27989 18.4967 0.797557C17.3402 1.31522 \n",
       "        16.3043 2.06823 15.4551 3.00856C14.49 4.08707 13.7984 5.38193 13.4389 6.78385C13.0794 8.18576 13.0624 9.6536 \n",
       "        13.3894 11.0635C13.52 11.593 13.6984 12.1095 13.9225 12.6067C14.5595 14.0514 15.4951 15.3681 16.284 \n",
       "        16.7355C17.2525 18.4147 18.2209 20.0948 19.1893 21.7758C20.1578 23.4568 21.1351 25.1449 22.1213 \n",
       "        26.8401C22.9209 28.2421 23.7925 29.4682 23.8805 31.1528C23.9175 32.0513 23.7682 32.9479 23.4419 \n",
       "        33.7859C23.1156 34.6239 22.6194 35.3854 21.9845 36.0223C21.3496 36.6592 20.5897 37.1578 19.7527 \n",
       "        37.4868C18.9157 37.8157 18.0196 37.9678 17.121 37.9336C14.0024 37.7923 11.6488 35.4814 11.1744 32.4588C10.58 \n",
       "        28.6419 13.552 26.5469 13.552 26.5469C14.1782 26.1785 14.6497 25.5955 14.8791 24.906C15.1084 24.2166 15.0801 \n",
       "        23.4673 14.7993 22.7971C14.5186 22.127 14.0044 21.5813 13.3521 21.2611C12.6998 20.941 11.9536 20.8682 11.2517 \n",
       "        21.0561C11.1174 21.0939 10.9856 21.1402 10.8572 21.1947\" fill=\"white\" /> <path d=\"M42.8101 31.5968C42.8109 \n",
       "        30.5198 42.7218 29.4445 42.5435 28.3823C42.2663 26.7069 41.7464 25.0808 41.0002 23.5552C40.5524 22.6463 \n",
       "        39.9874 21.7374 39.1024 21.2417C38.6593 20.9919 38.1589 20.8617 37.6502 20.8639C37.1416 20.8661 36.6423 \n",
       "        21.0006 36.2013 21.2541C35.7604 21.5077 35.393 21.8716 35.1352 22.3101C34.8775 22.7485 34.7382 23.2466 \n",
       "        34.7312 23.7552C34.7072 24.8773 35.3149 25.8875 35.768 26.9217C36.5212 28.6453 36.8623 30.5208 36.7642 \n",
       "        32.3993C36.6661 34.2777 36.1315 36.1075 35.2029 37.7433C35.146 37.8404 35.0952 37.941 35.051 38.0445C34.8623 \n",
       "        38.4842 34.7635 38.9573 34.7605 39.4358C34.7802 40.1222 35.0356 40.7808 35.4835 41.3011C35.9315 41.8214 \n",
       "        36.5449 42.1717 37.2207 42.2932C38.8759 42.589 40.1899 41.347 40.8856 39.9609C42.1643 37.3589 42.823 34.4961 \n",
       "        42.8101 31.5968Z\" fill=\"white\" /> <path d=\"M28.2309 11.8938C28.1761 11.9043 28.1218 11.9176 28.0683 \n",
       "        11.9338C27.9593 11.9642 27.8611 12.0249 27.7851 12.1088C27.7091 12.1928 27.6584 12.2965 27.6389 \n",
       "        12.408C27.6193 12.5195 27.6318 12.6343 27.6748 12.7391C27.7178 12.8438 27.7895 12.9343 27.8818 \n",
       "        12.9999C29.2375 14.0252 30.3809 15.3043 31.2482 16.7662C31.4838 17.1677 31.6888 17.5865 31.8612 \n",
       "        18.0189C32.0052 18.3921 32.1971 18.8799 32.6822 18.8532C33.0607 18.8346 33.2153 18.512 33.3192 \n",
       "        18.1895C33.8137 16.5125 33.9678 14.7534 33.7723 13.0159C33.6331 12.0693 33.4155 11.1359 33.122 \n",
       "        10.2252C33.0775 10.0047 32.9744 9.80029 32.8235 9.6335C32.7273 9.54627 32.6054 9.49262 32.4761 9.4806C32.3468 \n",
       "        9.46859 32.2171 9.49886 32.1065 9.56687C32.0016 9.65188 31.9115 9.75365 31.8399 9.86806C31.3956 10.4658 \n",
       "        30.825 10.9581 30.1687 11.3101C29.8377 11.4861 29.4893 11.6272 29.1292 11.7312C28.828 11.8192 28.5215 11.8325 \n",
       "        28.2309 11.8938Z\" fill=\"white\" /> </svg> Display SwanLab Board </button> <br> <div \n",
       "        id=\"iframeContainer\"></div> </body> </html>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<swanlab.data.run.main.SwanLabRun at 0x7f8dceb30160>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import swanlab\n",
    "# 初始化swanlab，传入项目名、实验名等\n",
    "swanlab.init(\n",
    "    project=\"MiniMind-SFT\", \n",
    "    experiment_name=\"MiniMind-SFT\", \n",
    "    config=vars(TrainArgs()) # 将你的所有超参数配置一次性传给swanlab\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义训练epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(epoch, model, train_loader, optimizer, scaler, lm_config):\n",
    "    #选择初始化损失函数！\n",
    "    model.train() # 确保模型处于训练模式\n",
    "\n",
    "    loss_fct = nn.CrossEntropyLoss(reduction='none')\n",
    "\n",
    "    start_time = time.time()#一会记录日志要用\n",
    "\n",
    "    iter_per_epoch = len(train_loader)#看一下一次数据有多长，计算学习率要用\n",
    "\n",
    "    # --- 新增：使用tqdm包装DataLoader以显示进度条 ---\n",
    "    progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{TrainArgs.epochs}\", leave=True)\n",
    "\n",
    "    for step, (X, Y, loss_mask) in enumerate(progress_bar):#不断提取数据\n",
    "        X = X.to(TrainArgs.device)\n",
    "        Y = Y.to(TrainArgs.device)\n",
    "        loss_mask = loss_mask.to(TrainArgs.device)#数据上设备，上到gpu上\n",
    "\n",
    "        \n",
    "        lr = get_lr(epoch * iter_per_epoch + step, TrainArgs.epochs * iter_per_epoch, TrainArgs.learning_rate)\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = lr                #计算当前学习率的算法\n",
    "\n",
    "        with TrainArgs.ctx:\n",
    "            res = model(X)#得到的是logits，aux_loss\n",
    "\n",
    "            loss = loss_fct(\n",
    "                res.logits.view(-1, res.logits.size(-1)),\n",
    "                Y.view(-1)\n",
    "            ).view(Y.size())  #计算loss的算法\n",
    "            loss = (loss * loss_mask).sum() / loss_mask.sum()\n",
    "            loss += res.aux_loss\n",
    "            loss = loss / TrainArgs.accumulation_steps  \n",
    "\n",
    "            scaler.scale(loss).backward()  #反向传播\n",
    "\n",
    "        if (step + 1) % TrainArgs.accumulation_steps == 0:#判断梯度累加到位没有\n",
    "            scaler.unscale_(optimizer)#*前置操作\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), TrainArgs.grad_clip)\n",
    "            #梯度裁剪\n",
    "            scaler.step(optimizer)#参数更新\n",
    "            scaler.update()#*调整\n",
    "\n",
    "            optimizer.zero_grad(set_to_none=True)#本次训练结束，清零梯度，为下一次反向传播准备\n",
    "             \n",
    "            \n",
    "        if step % TrainArgs.log_interval == 0:\n",
    "            spend_time = time.time() - start_time\n",
    "            current_lr = optimizer.param_groups[0]['lr']\n",
    "            progress_bar.set_postfix({\n",
    "                \"loss\": f\"{loss.item():.3f}\",\n",
    "                \"lr\": f\"{current_lr:.2e}\"\n",
    "            })\n",
    "\n",
    "            if (swanlab is not None) : #用日志软件记录训练过程\n",
    "                swanlab.log({\"loss\": loss.item() ,\n",
    "                           \"lr\": optimizer.param_groups[0]['lr'],\n",
    "                           \"epoch_Time\": spend_time / (step + 1) * iter_per_epoch // 60 - spend_time // 60})\n",
    "\n",
    "            # 保存checkpoint\n",
    "        if (step + 1) % TrainArgs.save_interval == 0:\n",
    "            # 只在更新步之后保存，确保梯度累积完成\n",
    "            if (step + 1) % TrainArgs.accumulation_steps == 0:\n",
    "                model.eval()\n",
    "                print(f\"\\nSaving checkpoint at step {step+1}...\")\n",
    "                \n",
    "                # 创建checkpoint字典\n",
    "                checkpoint = {\n",
    "                    \n",
    "                    'model': model.state_dict(),  # 保留原始精度\n",
    "                    'optimizer': optimizer.state_dict(),\n",
    "                    'scaler': scaler.state_dict(),\n",
    "                    'epoch': epoch,\n",
    "                    'step': step,\n",
    "                    'config': TrainArgs,\n",
    "                }\n",
    "                \n",
    "                # 保存\n",
    "                torch.save(checkpoint, TrainArgs.checkpoint_path)\n",
    "                print(\"Checkpoint saved.\")\n",
    "                model.train() # 切换回训练模式\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 实现循环训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Starting from scratch...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MiniMindForCausalLM(\n",
       "  (model): MiniMindModel(\n",
       "    (embed_tokens): Embedding(6400, 512)\n",
       "    (dropout): Dropout(p=0.0, inplace=False)\n",
       "    (layers): ModuleList(\n",
       "      (0-7): 8 x MiniMindBlock(\n",
       "        (self_attn): Attention(\n",
       "          (q_proj): Linear(in_features=512, out_features=512, bias=False)\n",
       "          (k_proj): Linear(in_features=512, out_features=128, bias=False)\n",
       "          (v_proj): Linear(in_features=512, out_features=128, bias=False)\n",
       "          (o_proj): Linear(in_features=512, out_features=512, bias=False)\n",
       "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (input_layernorm): RMSNorm()\n",
       "        (post_attention_layernorm): RMSNorm()\n",
       "        (mlp): FeedForward(\n",
       "          (gate_proj): Linear(in_features=512, out_features=1408, bias=False)\n",
       "          (down_proj): Linear(in_features=1408, out_features=512, bias=False)\n",
       "          (up_proj): Linear(in_features=512, out_features=1408, bias=False)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (norm): RMSNorm()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=512, out_features=6400, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- 关键：Checkpoint加载逻辑 ---\n",
    "start_epoch = 0\n",
    "start_step = 0\n",
    "if os.path.exists(TrainArgs.checkpoint_path):\n",
    "    print(f\"=> Resuming from checkpoint: {TrainArgs.checkpoint_path}\")\n",
    "    checkpoint = torch.load(TrainArgs.checkpoint_path, map_location=TrainArgs.device)\n",
    "    \n",
    "    # 加载模型权重 (处理DDP保存的权重)\n",
    "    model_state_dict = checkpoint['model']\n",
    "    if any(key.startswith('module.') for key in model_state_dict):\n",
    "            model_state_dict = {k.replace('module.', ''): v for k, v in model_state_dict.items()}\n",
    "    model.load_state_dict(model_state_dict)\n",
    "    \n",
    "    # 加载优化器和scaler状态\n",
    "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "    scaler.load_state_dict(checkpoint['scaler'])\n",
    "    \n",
    "    # 恢复训练进度\n",
    "    start_epoch = checkpoint['epoch']\n",
    "    # 注意：恢复step逻辑可以让dataloader跳过已训练数据，这里简化为从头开始当前epoch\n",
    "    print(f\"=> Resumed from epoch {start_epoch + 1}\")\n",
    "else:\n",
    "    print(\"=> Starting from scratch...\")\n",
    "\n",
    "model.to(TrainArgs.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3140d7cdfedd4f53afdec6fbfe31ed76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/2:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e431e2d0ca54c38a7beda6cb10ef935",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/2:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#测试训练运行以下代码\n",
    "for epoch in range(start_epoch, TrainArgs.epochs):\n",
    "        train_epoch(epoch, model, test_loader, optimizer, scaler, lm_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92afd741fa3743a0b8fdb8a202c3b0f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/2:   0%|          | 0/32785 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving checkpoint at step 2000...\n",
      "Checkpoint saved.\n",
      "\n",
      "Saving checkpoint at step 4000...\n",
      "Checkpoint saved.\n",
      "\n",
      "Saving checkpoint at step 6000...\n",
      "Checkpoint saved.\n",
      "\n",
      "Saving checkpoint at step 8000...\n",
      "Checkpoint saved.\n",
      "\n",
      "Saving checkpoint at step 10000...\n",
      "Checkpoint saved.\n",
      "\n",
      "Saving checkpoint at step 12000...\n",
      "Checkpoint saved.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#正式训练运行以下代码\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(start_epoch, TrainArgs\u001b[38;5;241m.\u001b[39mepochs):\n\u001b[0;32m----> 3\u001b[0m         \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscaler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlm_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[12], line 15\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[0;34m(epoch, model, train_loader, optimizer, scaler, lm_config)\u001b[0m\n\u001b[1;32m     12\u001b[0m progress_bar \u001b[38;5;241m=\u001b[39m tqdm(train_loader, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mTrainArgs\u001b[38;5;241m.\u001b[39mepochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, leave\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, (X, Y, loss_mask) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(progress_bar):\u001b[38;5;66;03m#不断提取数据\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mTrainArgs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m     Y \u001b[38;5;241m=\u001b[39m Y\u001b[38;5;241m.\u001b[39mto(TrainArgs\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m     17\u001b[0m     loss_mask \u001b[38;5;241m=\u001b[39m loss_mask\u001b[38;5;241m.\u001b[39mto(TrainArgs\u001b[38;5;241m.\u001b[39mdevice)\u001b[38;5;66;03m#数据上设备，上到gpu上\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#正式训练运行以下代码\n",
    "for epoch in range(start_epoch, TrainArgs.epochs):\n",
    "        train_epoch(epoch, model, train_loader, optimizer, scaler, lm_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_ds' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgc\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m train_ds, train_loader  \u001b[38;5;66;03m# 解除引用\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# 2. 清空PyTorch内部缓存\u001b[39;00m\n\u001b[1;32m      7\u001b[0m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mempty_cache()  \u001b[38;5;66;03m# 释放GPU显存\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_ds' is not defined"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import gc\n",
    "\n",
    "del train_ds, train_loader  # 解除引用\n",
    "\n",
    "# 2. 清空PyTorch内部缓存\n",
    "torch.cuda.empty_cache()  # 释放GPU显存\n",
    "\n",
    "# 3. 触发Python垃圾回收（确保循环引用被清理）\n",
    "gc.collect()  # 强制回收内存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU显存占用: 21000.05 MB\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print(f\"GPU显存占用: {torch.cuda.memory_allocated() / 1024**2:.2f} MB\") \n",
    "\n",
    "# 检查对象是否已被销毁\n",
    "print('train_ds' in locals()) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_proj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
